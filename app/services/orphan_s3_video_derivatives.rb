# This service class looks at all the folders (or s3 prefixes -- same thing) in the s3 folder where we store our
# video derivatives, and attempts to connect each folder to a current video original. Folders that can't be accounted
# for can be either listed out or deleted.
#
# No individual files within these folders are examined; if a folder can't be connected to a video asset, the entire folder is considered an orphan.
# Individual files stored directly under the top-level `hls/` directory do not belong: they are also treated as orphans.
#
# bundle exec rails runner 'OrphanS3VideoDerivatives.new(show_progress_bar: false).report_orphans'
# bundle exec rails runner 'OrphanS3VideoDerivatives.new(show_progress_bar: false).delete_orphans'
class OrphanS3VideoDerivatives

  attr_reader :s3_iterator, :shrine_storage, :show_progress_bar, :sample, :orphans_found
  def initialize(show_progress_bar: true)

    @sample = []
    @shrine_storage = ScihistDigicoll::Env.shrine_video_derivatives_storage
    @show_progress_bar = show_progress_bar

    @s3_iterator = S3PathIterator.new(
      extra_prefix: 'hls/',
      first_level_only: true,
      shrine_storage: shrine_storage,
      show_progress_bar: show_progress_bar,
      progress_bar_total: video_derivative_count,
    )
  end

  def video_derivative_count
    @video_derivative_count ||= Kithe::Asset.connection.select_one("select count((json_attributes->'hls_playlist_file_data' #>> '{}')::jsonb->>'id') from kithe_models where (json_attributes->'hls_playlist_file_data' #>> '{}')::jsonb->>'id' !='';")['count']
  end

  # Lists any orphan HLS derivatives found.
  def report_orphans
    max_reports = 20
    @orphans_found = 0
    files_checked = find_orphan_video_derivatives do |asset_id:, shrine_id:, s3_path:|
      @orphans_found +=1
      if @orphans_found == max_reports
        s3_iterator.log "Reported max #{max_reports} orphans, not listing subsquent...\n"
      elsif @orphans_found < max_reports
        @sample << s3_url_for_path(s3_path)
        asset = Asset.where(id: asset_id).first
        s3_iterator.log "set of orphaned HLS derivatives"
        s3_iterator.log "  bucket: #{shrine_storage.bucket.name}"
        s3_iterator.log "  s3 path: #{s3_path}"
        s3_iterator.log "  asset_id: #{asset_id}"
        s3_iterator.log "  asset missing"  if asset.nil?
        s3_iterator.log ""
      end
    end

    $stderr.puts "\n\nTotal video derivative count from the database: #{video_derivative_count}"
    $stderr.puts "Iterated through #{files_checked} video derivatives on S3"
    $stderr.puts "Found #{orphans_found} orphaned items\n"
  end

  # Delete all files and folders that can't be accounted for
  # as HLS derivatives.
  def delete_orphans
    delete_count = 0
    find_orphan_video_derivatives do |asset_id:, shrine_id:, s3_path:|
      shrine_storage.delete_prefixed(shrine_id)
      s3_iterator.log "deleted: #{shrine_storage.bucket.name}: #{s3_path}"
      delete_count += 1
    end
    $stderr.puts "\nDeleted #{delete_count} sets of orphaned derivatives"
  end


  # Yields to the caller an s3 path for each hls derivative folder on s3.
  # We expect each of these to contain exactly one `hls.m3u8` manifest file,
  # as well as dozens to hundreds of actual derivative files.
  def all_hls_deriv_folders
    # First iterate over all video derivs in s3.
    s3_iterator.each_s3_path do |all_derivs_for_asset|
      # all_derivs_for_asset is an s3 folder containing
      # all HLS derivatives for a particular asset.
      # The path ends in the asset id, e.g.
      # laptop.local/derivatives_video/hls/0eadfd9b-c36b-4b02-a5e1-63a00a259410/
      S3PathIterator.new(
        extra_prefix: remove_prefix(all_derivs_for_asset),
        first_level_only: true,
        shrine_storage: shrine_storage,
        show_progress_bar: false,
      ).each_s3_path do |set_of_hls_derivs|
        # set_of_hls_derivs is an individual folder containing all the hls derivatives
        # generated by a particular request to mediaconvert, e.g.:
        # laptop.local/derivatives_video/hls/0eadfd9b-c36b-4b02-a5e1-63a00a259410/2160f6d44ed781f81e7a4a66d5a0b117/
        yield set_of_hls_derivs
      end
    end
  end


  # List all HLS derivatives in the database. This is practical because we do not anticipate
  # ever ingesting more than a few hundred videos into the digital collections.
  #
  #
  # See infrastructure/aws-mediaconvert/README.md for more details
  # (including links to GitHub and the wiki) about
  # what goes in json_attributes->'hls_playlist_file_data'.
  def get_hls_derivs_from_db
      query = [
        # hls_playlist_file_data key and value are escaped and
        # stored as a string, so we need to extract the filepath using a trick described at 
        # https://dev.to/mrmurphy/so-you-put-an-escaped-string-into-a-json-column-2n67.
        "select (json_attributes->'hls_playlist_file_data' #>> '{}')::jsonb->>'id' as hls_info",
        
        # from assets
        "from kithe_models where kithe_model_type = 2",
        
        # of type video
        "and file_data ->> 'storage' = 'video_store'"

      ].join(" ")

      Kithe::Asset.connection.select_all(query).rows.map{|r| r[0]}.compact
  end

  private

  # Will yield to block (asset_id, shrine_id, s3_path) for each derivative
  # determined to be an orphan.
  def find_orphan_video_derivatives
    hls_derivs_from_db = get_hls_derivs_from_db    
    all_hls_deriv_folders do |s3_path|
      shrine_id = remove_prefix(s3_path)
      unless hls_derivs_from_db.include? "#{shrine_id}hls.m3u8"
        # orphan found!
        hls, asset_id, hls_random_string = shrine_id.split('/')
        yield asset_id: asset_id, shrine_id: shrine_id, s3_path: s3_path
      end
    end
  end

  def bucket_prefix
    @bucket_prefix ||= if shrine_storage.prefix
      Regexp.escape(shrine_storage.prefix.chomp('/') + '/')
    else
      ''
    end
  end


  # We're not interested in the storage_prefix. What we want is what
  # shrine thinks of as the path on S3, and our way of accessing
  # and deleting the file if we determine it to be orphaned.
  def remove_prefix(s3_path)
    return s3_path if shrine_storage.prefix.nil?
    s3_path.delete_prefix(shrine_storage.prefix + "/")
  end


  # Note that the s3_path is the complete path on bucket. This might include a prefix
  # from the shrine storage already. For our report in the admin pages,
  # we just want a functioning URL that takes us directly to S3 if we need to investigate.
  def s3_url_for_path(s3_path)
    if shrine_storage.respond_to?(:bucket)
      shrine_storage.bucket.object(s3_path).public_url
    else
      shrine_storage.url(s3_path)
    end
  end
end