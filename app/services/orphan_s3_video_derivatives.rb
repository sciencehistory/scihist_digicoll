# This service class looks at s3 prefixes in the top two levels of our video derivatives,
# and attempts to connect each folder to a legitimate HLS manifest file.
#
# Folders that can't be accounted for can be either listed or deleted.
#
# 1) We are working at the folder level: if a folder can't be associated with a derivative,
# the entire folder is considered orphaned and can be deleted as a unit.
#
# 2) Individual files stored directly under the top-level
# `[...]/derivatives_video/hls/` folder should not be there; they're treated as orphans.
#
# 3) We do not sift through any of the contents of the folders beyond
# the top two levels. Thus, any extraneous files that somehow end up
# inside an asset's legitimate HLS derivative folder
# [...]/derivatives_video/hls/asset_id/random_string/misplaced_file.txt
# will NOT be detected as orphans.
#
# bundle exec rails runner 'OrphanS3VideoDerivatives.new(show_progress_bar: false).report_orphans'
# bundle exec rails runner 'OrphanS3VideoDerivatives.new(show_progress_bar: false).delete_orphans'
class OrphanS3VideoDerivatives

  attr_reader :s3_iterator, :shrine_storage, :show_progress_bar, :sample, :orphans_found
  def initialize(show_progress_bar: true)

    @sample = []
    @shrine_storage = ScihistDigicoll::Env.shrine_video_derivatives_storage
    @show_progress_bar = show_progress_bar

    @s3_iterator = S3PathIterator.new(
      extra_prefix: 'hls/',
      first_level_only: true,
      shrine_storage: shrine_storage,
      show_progress_bar: show_progress_bar,
      progress_bar_total: video_derivative_count,
    )
  end

  def video_derivative_count
    @video_derivative_count ||= get_hls_derivs_from_db.count
  end

  # Lists any orphan HLS derivatives found.
  def report_orphans
    max_reports = 20
    @orphans_found = 0
    files_checked = find_orphan_video_derivatives do |asset_id:, shrine_id:, s3_path:|
      @orphans_found +=1
      if @orphans_found == max_reports
        s3_iterator.log "Reported max #{max_reports} orphans, not listing subsquent...\n"
      elsif @orphans_found < max_reports
        @sample << s3_url_for_path(s3_path)
        asset = Asset.where(id: asset_id).first
        s3_iterator.log "set of orphaned HLS derivatives"
        s3_iterator.log "  bucket: #{shrine_storage.bucket.name}"
        s3_iterator.log "  s3 path: #{s3_path}"
        s3_iterator.log "  asset_id: #{asset_id}"
        s3_iterator.log "  path of actual HLS manifest: #{asset&.hls_playlist_file_data['id']}" unless asset.nil?
        s3_iterator.log "  asset missing"  if asset.nil?
        s3_iterator.log ""
      end
    end

    $stderr.puts "\n\nTotal video derivative count from the database: #{video_derivative_count}"
    $stderr.puts "Iterated through #{files_checked} video derivatives on S3"
    $stderr.puts "Found #{orphans_found} orphaned items\n"
  end

  # Delete all files and folders that can't be accounted for
  # as HLS derivatives.
  def delete_orphans
    delete_count = 0
    find_orphan_video_derivatives do |asset_id:, shrine_id:, s3_path:|
      shrine_storage.delete_prefixed(shrine_id)
      s3_iterator.log "deleted: #{shrine_storage.bucket.name}: #{s3_path}"
      delete_count += 1
    end
    $stderr.puts "\nDeleted #{delete_count} sets of orphaned derivatives"
  end


  # Yields to the caller s3 paths for files or folders at the top two levels of the hls folder.
  # This does result in a lot of calls to `list_objects_v2` under the hood - on the order of one per video asset
  # in the digital collections. This is fine, because the calls are very cheap.
  def top_two_levels_of_hls_folder
    # First iterate over all video derivs in s3.
    s3_iterator.each_s3_path do |top_level_path|
      if top_level_path.end_with?('/')
        S3PathIterator.new(
          extra_prefix: remove_prefix(top_level_path),
          first_level_only: true,
          shrine_storage: shrine_storage,
          show_progress_bar: false,
        ).each_s3_path do |second_level_path|
          yield second_level_path
        end
      else
        # There should not be any stray single files directly under the /hls directory.
        # Yield this file so it can be reported as an orphan.
        yield top_level_path
      end
    end
  end


  # Return a list of legitimate manifest files, each of the form:
  # [...]/derivatives_video/hls/asset_id/random_string/hls.m3u8 .
  #
  # It's important to note that the random_string is arbitrary and
  # generated by Mediaconvert at deriv generation time.
  #
  # See infrastructure/aws-mediaconvert/README.md for more details
  # (including links to GitHub and the wiki) about
  # what goes in json_attributes->'hls_playlist_file_data'.
  def get_hls_derivs_from_db
      query = [
        "select json_attributes->'hls_playlist_file_data'->'id'",
        
        # from assets
        "from kithe_models where kithe_model_type = 2",
        
        # of type video
        "and file_data ->> 'storage' = 'video_store'",

        # where the value exists
        "and json_attributes->'hls_playlist_file_data'->'id' is not NULL"

      ].join(" ")

      Asset.connection.select_all(query).rows.map{ |r| r[0].delete_prefix('"').delete_suffix('"') }
  end

  private

  # Yields (asset_id, shrine_id, s3_path) for each derivative
  # determined to be an orphan.
  def find_orphan_video_derivatives
    hls_derivs_from_db = get_hls_derivs_from_db    
    top_two_levels_of_hls_folder do |s3_path|
      # At this point, s3_path should refer to a folder containing all
      # HLS derivatives (including all bitrates) for a particular asset.
      #
      # The last two elements of the path are the asset ID and a random string
      # generated by Mediaconvert.
      # [...]/derivatives_video/hls/asset_id/random_string/ .
      #
      # hls_derivs_from_db contains a list of legitimate manifest files, each of the form:
      # [...]/derivatives_video/hls/asset_id/random_string/hls.m3u8 .
      # If the combination of asset_id and random_string
      # (plus the manifest filename hls.m3u8 )
      # cannot be found in hls_derivs_from_db,
      # we report s3_path as an orphan.
      shrine_id = remove_prefix(s3_path)
      unless hls_derivs_from_db.include? "#{shrine_id}hls.m3u8"
        hls, asset_id, hls_random_string = shrine_id.split('/')
        # hls is the string "hls"
        # random_string is arbitrary
        yield asset_id: asset_id, shrine_id: shrine_id, s3_path: s3_path
      end
    end
  end

  def bucket_prefix
    @bucket_prefix ||= if shrine_storage.prefix
      Regexp.escape(shrine_storage.prefix.chomp('/') + '/')
    else
      ''
    end
  end


  # We're not interested in the storage_prefix. What we want is what
  # shrine thinks of as the path on S3, and our way of accessing
  # and deleting the file if we determine it to be orphaned.
  def remove_prefix(s3_path)
    return s3_path if shrine_storage.prefix.nil?
    s3_path.delete_prefix(shrine_storage.prefix + "/")
  end


  # Note that the s3_path is the complete path on bucket. This might include a prefix
  # from the shrine storage already. For our report in the admin pages,
  # we just want a functioning URL that takes us directly to S3 if we need to investigate.
  def s3_url_for_path(s3_path)
    if shrine_storage.respond_to?(:bucket)
      shrine_storage.bucket.object(s3_path).public_url
    else
      shrine_storage.url(s3_path)
    end
  end
end