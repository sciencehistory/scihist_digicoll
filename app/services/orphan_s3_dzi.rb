# DZI files (https://en.wikipedia.org/wiki/Deep_Zoom) are stored on S3 using
# a keypath template:
#
#     ./{asset uuid}/md5_{md5 hash}.dzi
#     ./{asset uuid}/md5_{md5 hash}_files/{lots of tiles}
#
# The `md5_{md5 hash}.dzi` manifest file corresponds to an `md5_{md5 hash}_files/` directory full of
# hieararchical tiles; this is part of the DZI format.
#
# This class will use S3 API to iterate through the top two levels of the dzi file hierarchy.
# First we look at at the top level to find all `{uuid}/` folders.
# Then, for each legitimate top level folder,
# we look at files or folders that look like either a manifest ( md5_{md5 hash}.dzi )
# or a folder full of tiles (md5_{md5 hash}_files/ ).
#
# The second-level check is only run if the top-level directory is not an orphan directory:
# in other words, if the top-level directory can be connected to a legitimate asset in the database.
#
# The nested iteration takes around 12 minutes to run on our EC2 instances,
# and costs around 12 cents every time you run it.
# The time and cost could be reduced significantly if we reorganized the keypath arrangement.
#
# We could consider switching to a layout more like chf_sufia used, where there isn't
# an `{asset uuid}/` component in the path, but all .dzi files and _files folders
# are siblings next to each other, and the asset uuid is encoded directly in the .dzi/_files name.
# It turns out that makes it much more convenient to more quickly find just the top-level .dzi
# files, using the S3 'delimiter' API. And allows report/delete in more like 5 minutes. But
# would require a reorganization of our many gigs of DZI files, which is hard to do on S3.
#
# It's important to note that no orphans BELOW the first two levels will be detected.
# If someone somehow managed to sneak extraneous files inside e.g.
# ./{asset uuid}/md5_{md5 hash}_files/path/to/evil_files , we would not be able to detect them
# as orphans and they would continue to lurk there indefinitely.
#
# The rapid rate of delete requests generated by a `delete_orphans` job
# sometimes causes s3 to throw a `Aws::S3::Errors::SlowDown (Please reduce your request rate.)`.
# (See https://github.com/sciencehistory/scihist_digicoll/issues/1653 ).
# In the aftermath, you will typically find the .dzi manifest files have been correctly deleted, but
# the actual tiles in the orphaned tile directories are still lying around.
#
# This code has been rewritten so that orphaned tile directories
# are detected, even in the absence of a .dzi manifest.
#
# bundle exec rails runner 'OrphanS3Dzi.new(show_progress_bar: false).report_orphans'
# bundle exec rails runner 'OrphanS3Dzi.new(show_progress_bar: false).delete_orphans'
class OrphanS3Dzi

  attr_reader :s3_iterator, :shrine_storage, :show_progress_bar, :sample, :orphans_found
  def initialize(show_progress_bar: true)
    @sample = []
    @shrine_storage = ScihistDigicoll::Env.shrine_dzi_storage
    @show_progress_bar = show_progress_bar
    @s3_iterator = S3PathIterator.new(
      shrine_storage: shrine_storage,
      show_progress_bar: show_progress_bar,
      progress_bar_total: asset_count,
      first_level_only: true
    )
  end

  def asset_count
    @asset_count ||= Asset.count
  end

  def delete_orphans
    delete_count = 0
    find_orphan_dzi_files do |found_asset:, asset_id:, md5:, shrine_id:, s3_path:|
      if shrine_id.end_with? "/"
        shrine_storage.delete_prefixed(shrine_id)
        what_was_deleted = "a folder and its contents"
      else
        shrine_storage.delete(shrine_id)
        what_was_deleted = "a single orphan file     "
      end
        s3_iterator.log "deleted #{what_was_deleted} at #{shrine_storage.bucket.name}: #{s3_path}"
      delete_count += 1
    end
    $stderr.puts "\nDeleted #{delete_count} files or folders from DZI."
  end


  def report_orphans
    max_reports = 20
    @orphans_found = 0

    files_checked = find_orphan_dzi_files do |found_asset:, asset_id:, md5:, shrine_id:, s3_path:|
      @orphans_found +=1

      if @orphans_found == max_reports
        s3_iterator.log "Reported max #{max_reports} orphans, not listing subsquent...\n"
      elsif @orphans_found < max_reports

        @sample << s3_url_for_path(s3_path)

        s3_iterator.log "orphaned file or folder under the DZI folder."
        s3_iterator.log "  bucket: #{shrine_storage.bucket.name}"
        s3_iterator.log "  file or folder path: #{s3_path}"
        s3_iterator.log "  asset_id: #{asset_id}"
        s3_iterator.log "  expected md5: #{md5}"             if md5
        s3_iterator.log "  actual md5:   #{found_asset.md5}" if found_asset
        s3_iterator.log "  asset missing"                    unless found_asset

        s3_iterator.log ""
      end
    end

    $stderr.puts "\n\nTotal Asset count: #{asset_count}"
    $stderr.puts "Checked #{files_checked} top level directories under dzi/ ."
    $stderr.puts "Found #{orphans_found} orphan files or folders.\n"
  end

  # Given an s3_path, return an S3PathIterator that
  # yields all full s3 paths for the
  # the files or folders exactly one level underneath s3_path.
  # In the normal case this is one file (the dzi manifest file)
  # and one folder (containing all the actual tiles).
  def sub_iterator(s3_path)
    S3PathIterator.new(
      shrine_storage: shrine_storage,
      extra_prefix: s3_path.split("/").last,
      show_progress_bar: false, first_level_only: true
    )
  end

  private

  # Iterate over the top two levels of the "dzi/" folder.
  # Yield to block (asset_id, md5, shrine_id, s3_path) for each file or directory
  # determined to be an orphan.
  #
  # @yield [asset_id:, md5:, shrine_id:, s3_path:]
  def find_orphan_dzi_files
    s3_iterator.each_s3_path do |top_s3_path|
      # Start at the top level, directly under "dzi/".
      # Each of the folders at this level should be named
      # after the uuid of of an existing asset.
      # 1. Can we find a current asset with that uuid ?
      found_asset = look_up_asset_from_top_level_s3_path(top_s3_path)
      if found_asset.nil?
        # No asset found. This entire directory can be considered orphaned.
        # No need to dig any further.
        asset_id, md5, shrine_id = parse_s3_path(top_s3_path)
        yield found_asset: nil, asset_id: asset_id, md5: md5, shrine_id: shrine_id, s3_path: top_s3_path
      else
        # 2. Great. We found an asset for this folder.
        # Let's dig one level down and see if we find what we expect.
        pattern = expected_second_level_folder_pattern(found_asset)
        sub_iterator(top_s3_path).each_s3_path do |s3_path|
          unless s3_path.match pattern
            asset_id, md5, shrine_id = parse_s3_path(s3_path)
            yield found_asset: found_asset, asset_id: asset_id, md5: md5, shrine_id: shrine_id, s3_path: s3_path
          end
        end
      end
    end
  end

  def look_up_asset_from_top_level_s3_path(top_s3_path)
    asset_id = top_s3_path.delete_prefix(bucket_prefix).chomp('/')
    Asset.where(id: asset_id).first
  end

  # Given an asset, returns a pattern that matches either of:
  #     {bucket_prefix}{asset uuid}/{expected_path}.dzi
  #     {bucket_prefix}{asset uuid}/{expected_path}_files/
  #
  # Expected path is stored inside the asset
  def expected_second_level_folder_pattern(asset)
    path_prefix = asset.dzi_manifest_file.id.gsub(/\.dzi$/, '')
    # eg "386122f1-19af-4b84-a641-9e1814be1824/md5_a5d00feca441d17c5e27c663693d38cd.dzi" with .dzi removed

    /^#{bucket_prefix}#{path_prefix}(\.dzi|_files\/)$/
  end

  # Only used in dev, as of current implementation.
  # Example: erubeiz.eddie-m1-laptop.local/dzi/
  # Includes a trailing slash.
  def bucket_prefix
    @bucket_prefix ||= if shrine_storage.prefix
      shrine_storage.prefix.chomp('/') + '/'
    else
      ""
    end
  end

  # Given a path to what we think is a DZI file or folder
  # on S3, attempt to extract the ID of the asset and its md5.
  def parse_s3_path(s3_path)
    shrine_id = s3_path.delete_prefix(bucket_prefix)
    asset_uuid, folder_or_filename =  shrine_id.split("/")
    md5 = extract_md5_from_folder_or_filename(folder_or_filename)
    [asset_uuid, md5, shrine_id]
  end

  # Given the last chunk of a typical S3 path for a DZI file or folder:
  #     "md5_MD5_HASH.dzi"
  #     "md5_MD5_HASH_files/"
  # return just the md5 hash that we can check against the asset's metadata.
  # Or return nil, if there doesn't appear to be one.
  def extract_md5_from_folder_or_filename(str)
    str.split(/\.|_/)[1] unless str.nil?
  end

  # Note that the s3_path is complete path on bucket. It might include a prefix
  # from the shrine storage already. We just want a complete good direct to S3 URL
  # as an identifier, it may not be accessible, it wont' use a CDN, etc.
  def s3_url_for_path(s3_path)
    if shrine_storage.respond_to?(:bucket)
      shrine_storage.bucket.object(s3_path).public_url
    else
      # we aren't S3 at all, not sure what we'll get...
      shrine_storage.url(s3_path)
    end
  end
end
