# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file

<% if ScihistDigicoll::Env.production? %>
# Link to sitemap
Sitemap: https://s3.amazonaws.com/<%= ScihistDigicoll::Env.lookup("s3_sitemap_bucket") %>/<%= ScihistDigicoll::Env.lookup("sitemap_path") %>sitemap.xml.gz

# Disallow some sort of search 'extra' that there is really no reason to be web crawling.
# Both from /catalog, and off various /collections/$collection_id pages.
User-agent: *
# "more facets"
Disallow: /catalog/facet/
Disallow: /collections/*/facet/
Disallow: /focus/*/facet
# range-limit page normally only requested by AJAX for loading range limit info.
Disallow: /catalog/range_limit
Disallow: /collections/*/range_limit
Disallow: /focus/*/range_limit
# "View larger" link for range limit.
Disallow: /catalog/range_limit_panel
Disallow: /collections/*/range_limit_panel
Disallow: /focus/*/range_limit_panel

# OK, let's try to disallow any search results that include facet limits,
# to try to prevent these crawlers from tree-walking every possible
# facet limit combination. 'nofollow' on the links would be my first choice
# instead of this, but waiting on PR to Blacklight for that.
# https://github.com/sciencehistory/scihist_digicoll/issues/1306
#
# Unclear if the [ should be %-encoded here, spec says yes,
# google robots.txt-validator suggests no, so we'll list both.
Disallow: /catalog*f%5B
Disallow: /catalog*f[
Disallow: /collections/*f%5B
Disallow: /collections/*f[
Disallow: /focus/*f%5B
Disallow: /focus/*f[

<%# Disallow all 'original' downloads EXCEPT PDFs. The others are too much
    bandwidth for no apparent purpose %>
Allow: /downloads/orig/pdf/
Disallow: /downloads/orig/


<%# PDF transcription and english_translation files are useless for robots,
   content is already in HTML %>
Disallow: /works/*/english_translation$
Disallow: /works/*/transcription$

<% else %>
# Non-production, no robots please, although we let twitter in to test twitter integration

# let twitter scrape cards metadata for testing
User-agent: Twitterbot
Disallow:

User-agent: *
Disallow: /
<% end %>
